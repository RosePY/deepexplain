{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TreeInterpreter Implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PUeUjGkJFzh"
      },
      "source": [
        "Install TreeInterpreter <br>\n",
        "[Github](https://github.com/andosa/treeinterpreter) <br>\n",
        "[Blog Explainer](http://blog.datadive.net/interpreting-random-forests/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiPM6GctJ14T"
      },
      "source": [
        "!pip install treeinterpreter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnonCA6jJSKJ"
      },
      "source": [
        "Setting up\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-MfppLtJOW9"
      },
      "source": [
        "from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        " #Load Dataset\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "#Set model type as Random Forest Regressor\n",
        "rf = RandomForestRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwIjFczqMGzh"
      },
      "source": [
        "#Calculating bias and feature prediction for two rows of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es-iMcrjMF9n"
      },
      "source": [
        "# Lets use the first 300 rows of data\n",
        "X = boston.data(:300) # Input Features\n",
        "y = boston.target(:300) # Target Vector\n",
        "rf.fit(boston.data[X, y) # Fit the model on X and y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzcvh_LDJTgl"
      },
      "source": [
        "instances = boston.data[[300, 309]]\n",
        "#print(instances) # Two rows of houses\n",
        "print (\"Instance 0 prediction:\", rf.predict([instances[0]]))\n",
        "print (\"Instance 1 prediction:\", rf.predict([instances[1]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezuAmjSyJXS9"
      },
      "source": [
        "# Use TreeInterpreter to caluclate bias and contributions\n",
        "prediction, bias, contributions = ti.predict(rf, instances)\n",
        "# Finding bias and contributions for each prediction \n",
        "for i in range(len(instances)):\n",
        "    print (\"Instance\", i)\n",
        "    print (\"Bias (trainset mean)\", bias[i])\n",
        "    print (\"Feature contributions:\")\n",
        "    for contri, feature in sorted(zip(contributions[i], \n",
        "                                 boston.feature_names), \n",
        "                             key=lambda x: -abs(x[0])):\n",
        "        print (feature, round(contri, 2))\n",
        "    print (\"-\"*20 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxwbWJ-tLcIA"
      },
      "source": [
        "Verifiying the methodology by - <br>\n",
        "Bias + Contribution = Prediction <br>\n",
        "Which proves correct. ( As seen by comapring with previously calculated values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeqGa5m2JdKI"
      },
      "source": [
        "print (prediction)\n",
        "print (bias + np.sum(contributions, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyFz6oK0L2fH"
      },
      "source": [
        "# Calculating feature contributions of the whole model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZprKWP2YK7IY"
      },
      "source": [
        "\n",
        "Splitting dataset into two (~100 rows)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vfLx0Y-Jdrx"
      },
      "source": [
        "ds1 = boston.data[300:400]\n",
        "ds2 = boston.data[400:]\n",
        " \n",
        "print (np.mean(rf.predict(ds1)))\n",
        "print (np.mean(rf.predict(ds2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygeNT2-4LPf_"
      },
      "source": [
        "Predicting biases and contributions for both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq2uRwdNJglp"
      },
      "source": [
        "prediction1, bias1, contributions1 = ti.predict(rf, ds1)\n",
        "prediction2, bias2, contributions2 = ti.predict(rf, ds2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkzcKpgiMUJY"
      },
      "source": [
        "Calculcating average contributions for each feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEKCukIwJmuh"
      },
      "source": [
        "totalc1 = np.mean(contributions1, axis=0) \n",
        "totalc2 = np.mean(contributions2, axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh5kt4GEJnYA"
      },
      "source": [
        "print (np.sum(totalc1 - totalc2))\n",
        "print (np.mean(prediction1) - np.mean(prediction2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji8-gV1yMrLo"
      },
      "source": [
        "The sum of the feature contribution differences should be equal to the difference in average prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h50LHU9pJpNA"
      },
      "source": [
        "for c, feature in sorted(zip(totalc1 - totalc2, \n",
        "                             boston.feature_names), reverse=True):\n",
        "    print (feature, round(c, 2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}